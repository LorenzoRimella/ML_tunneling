{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../data/Training_Dataset_2.xlsx\")\n",
    "\n",
    "data = data.values[:,1:]\n",
    "\n",
    "X = data[:,:-1].astype(float)\n",
    "mu = np.mean(X, axis = 0)\n",
    "std = np.std(X, axis = 0)\n",
    "X = (X - mu)/std\n",
    "\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y==\"E\",      np.zeros(y.shape), y)\n",
    "y = np.where(y==\"L\",  1 + np.zeros(y.shape), y)\n",
    "y = np.where(y==\"L \", 1 + np.zeros(y.shape), y)\n",
    "y = np.where(y==\"R\",  2 + np.zeros(y.shape), y)\n",
    "y = np.where(y==\"S\",  3 + np.zeros(y.shape), y)\n",
    "y = np.where(y==\"W\",  4 + np.zeros(y.shape), y)\n",
    "\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster_list = [\"gbtree\"]\n",
    "\n",
    "n_estimators_list  = [25, 50, 100, 150]\n",
    "\n",
    "eta_list = [0.1, 0.3, 0.7, 0.9]\n",
    "max_depth_list = [5, 10, 20, 30]\n",
    "\n",
    "lambda_list = [0.0, 1.0, 5.0]\n",
    "criterion_list  = [\"gini\", \"entropy\"]\n",
    "\n",
    "max_leaves_list   = [0, 1, 5]\n",
    "\n",
    "# accuracy_vector = -100 + np.zeros((len(booster_list), len(n_estimators_list), len(eta_list), len(max_depth_list), \n",
    "#                                    len(lambda_list), len(criterion_list), len(max_leaves_list) ))\n",
    "\n",
    "# for i1 in range(len(booster_list)):\n",
    "#     for i2 in range(len(n_estimators_list)):\n",
    "#         for i3 in range(len(eta_list)):\n",
    "#             for i4 in range(len(max_depth_list)):\n",
    "#                 for i5 in range(len(lambda_list)):\n",
    "#                     for i6 in range(len(criterion_list)):\n",
    "#                         for i7 in range(len(max_leaves_list)):\n",
    "\n",
    "#                                 clf = XGBClassifier(booster = booster_list[i1], \n",
    "#                                                     n_estimators = n_estimators_list[i2], \n",
    "#                                                     eta = eta_list[i3], \n",
    "#                                                     max_depth = max_depth_list[i4], \n",
    "#                                                     reg_lambda = lambda_list[i5], \n",
    "#                                                     criterion = criterion_list[i6], \n",
    "#                                                     max_leaves = max_leaves_list[i7],  )\n",
    "                                \n",
    "#                                 model = clf.fit(X_train, y_train)\n",
    "\n",
    "#                                 # Predict the labels for the test set\n",
    "#                                 y_pred = model.predict(X_test)\n",
    "\n",
    "#                                 # Calculate accuracy\n",
    "#                                 accuracy_vector[i1, i2, i3, i4, i5, i6, i7] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#                                 print(\"#####################\")\n",
    "#                                 print(\"booster \", booster_list[i1])\n",
    "#                                 print(\"n_estimators \", n_estimators_list[i2])\n",
    "#                                 print(\"eta \", eta_list[i3])\n",
    "#                                 print(\"max_depth \", max_depth_list[i4])\n",
    "#                                 print(\"lambda \", lambda_list[i5])\n",
    "#                                 print(\"criterion \", criterion_list[i6])\n",
    "#                                 print(\"max_leaves \", max_leaves_list[i7])\n",
    "#                                 print(accuracy_vector[i1, i2, i3, i4, i5, i6, i7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vector_XGB = np.load(\"accuracy_XGB.npy\")\n",
    "max_index = np.unravel_index(np.argmax(accuracy_vector_XGB), accuracy_vector_XGB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loren\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [18:04:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"criterion\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9459320288362513"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(booster = booster_list[max_index[0]], \n",
    "                    n_estimators = n_estimators_list[max_index[1]], \n",
    "                    eta = eta_list[max_index[2]], \n",
    "                    max_depth = max_depth_list[max_index[3]], \n",
    "                    reg_lambda = lambda_list[max_index[4]], \n",
    "                    criterion = criterion_list[max_index[5]], \n",
    "                    max_leaves = max_leaves_list[max_index[6]],  )\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list  = [25, 50, 100, 150]\n",
    "\n",
    "min_samples_split_list = [1, 2, 5]\n",
    "max_depth_list = [5, 10, 20, 30]\n",
    "\n",
    "min_samples_leaf_list = [1, 2, 5]\n",
    "criterion_list  = [\"gini\", \"entropy\"]\n",
    "\n",
    "\n",
    "# accuracy_vector_extra_tree = -100 + np.zeros((len(n_estimators_list), len(min_samples_split_list), len(max_depth_list), \n",
    "#                                               len(min_samples_leaf_list), len(criterion_list) ))\n",
    "\n",
    "# for i1 in range(len(n_estimators_list)):\n",
    "#     for i2 in range(len(min_samples_split_list)):\n",
    "#         for i3 in range(len(max_depth_list)):\n",
    "#             for i4 in range(len(min_samples_leaf_list)):\n",
    "#                 for i5 in range(len(criterion_list)):\n",
    "\n",
    "#                                 clf = ExtraTreesClassifier( n_estimators = n_estimators_list[i1], \n",
    "#                                                             min_samples_split = min_samples_split_list[i2], \n",
    "#                                                             max_depth = max_depth_list[i3], \n",
    "#                                                             min_samples_leaf = min_samples_leaf_list[i4], \n",
    "#                                                             criterion = criterion_list[i5],  )\n",
    "                                \n",
    "#                                 model = clf.fit(X_train, y_train)\n",
    "\n",
    "#                                 # Predict the labels for the test set\n",
    "#                                 y_pred = model.predict(X_test)\n",
    "\n",
    "#                                 # Calculate accuracy\n",
    "#                                 accuracy_vector_extra_tree[i1, i2, i3, i4, i5] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#                                 print(\"#####################\")\n",
    "#                                 print(\"n_estimators\", n_estimators_list[i1])\n",
    "#                                 print(\"min_samples_split\", min_samples_split_list[i2])\n",
    "#                                 print(\"max_depth\", max_depth_list[i3])\n",
    "#                                 print(\"min_samples_leaf\", min_samples_leaf_list[i4])\n",
    "#                                 print(\"criterion\", criterion_list[i5])\n",
    "#                                 print(accuracy_vector_extra_tree[i1, i2, i3, i4, i5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vector_ExtraTree = np.load(\"accuracy_ExtraTree.npy\")\n",
    "max_index = np.unravel_index(np.argmax(accuracy_vector_ExtraTree), accuracy_vector_ExtraTree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464469618949537"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier( n_estimators = n_estimators_list[max_index[0]], \n",
    "                            min_samples_split = min_samples_split_list[max_index[1]], \n",
    "                            max_depth = max_depth_list[max_index[2]], \n",
    "                            min_samples_leaf = min_samples_leaf_list[max_index[3]], \n",
    "                            criterion = criterion_list[max_index[4]],  )\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
